
================================
VQA-MED @ ImageClef 2020

Task 1: VQAnswering Task (VQA)
================================


Datasets:

- Training set: 4,000 images with 4,000 question-answer (QA) pairs.
- Validation set: 500 images with 500 QA pairs.

  Each folder contains: 1) QA_pairs.txt, (2) image folder, and (3) image_IDs.txt. 

- Test set: 500 images with 500 questions and reference answers.  

========================

The VQA-Med-2019 datasets could be used as additional training data: 
https://github.com/abachaa/VQA-Med-2019 

------------------------------------------------------------------------------
Website: https://www.imageclef.org/2020/medical/vqa/
AICrowd project: https://www.aicrowd.com/challenges/imageclef-2020-vqa-med-vqa
Mailing list: https://groups.google.com/d/forum/imageclef-vqa-med
------------------------------------------------------------------------------

Reference

If you use the VQA-Med 2020 dataset, please cite our paper: "Overview of the VQA-Med Task at ImageCLEF 2020: Visual Question Answering and Generation in the Medical Domain". Asma Ben Abacha, Vivek V. Datla, Sadid A. Hasan, Dina Demner-Fushman and Henning MÃ¼ller. CLEF 2020 Working Notes.

@Inproceedings{ImageCLEFVQA-Med2020,

author = {Asma {Ben Abacha} and Vivek V. Datla and Sadid A. Hasan and Dina Demner-Fushman and Henning M\"uller},
title = {Overview of the VQA-Med Task at ImageCLEF 2020: Visual Question Answering and Generation in the Medical Domain},

booktitle = {CLEF 2020 Working Notes},

series = {{CEUR} Workshop Proceedings},

year = {2020},

publisher = {CEUR-WS.org $<$http://ceur-ws.org$>$},

month = {September 22-25},

address = {Thessaloniki, Greece}
}

Contact Information
Asma Ben Abacha: asma.benabacha@nih.gov 
https://sites.google.com/site/asmabenabacha/
